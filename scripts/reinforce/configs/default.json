{
	"num_train_envs": 64,
	"num_train_env_procs": 16,
	"vec_env_type": "subproc",
	"device": "cuda",
	"num_train_steps": 20000000,
	"mode": "train",
	"log_dir": "./log",
	"traj_length": 10,
	"detach_gap": 10,
	"eval_freq": 50000,
	"num_eval_episodes": 10,
	"eval_stochastic": false,
	"env": {},
	"env_wrappers": [],
	"checkpoint_freq": 500000,
	"load_checkpoint_file": "",
	"teams": [],
	"default_teams": {
		"gamma": 0.99,
		"entropy_coeff": 0.0,
		"clip_grad_norm": 0.5,
		"value_hidden_size": 128,
		"policy_hidden_size": 64,
		"message_size": 64,
		"value_size": 32,
		"key_size": 16,
		"num_comm_rounds": 1,
		"temperature": 0.1,
		"global_comm_gate": false,
		"p2p_comm_gate": false,
		"comm_gate_gen": "gumbel_softmax",
		"use_supervised_policy_loss": false,
		"use_comm_gate_penalty_loss": false,
		"use_comm_gate_policy_loss": false,
		"gate_entropy_coeff": 0.0,
		"comm_penalty_curr_end": 0,
		"final_comm_penalty": 0,
		"comm_type": "maddpg",
		"value_comm_type": "maddpg",
		"optim_name": "Adam",
		"optim_kwargs": {},
		"activation": "tanh",
		"shared_reward_ratio": 0.0,
		"shared_comm_penalty_ratio": 1.0,
		"add_comm_penalty_to_return": true,
		"extra_comm_shared_ratio": 1.0,
		"use_comm_penalty_prob": 0.5,
		"forward_messages": true,
		"comm_penalty_type": "linear",
		"use_select_comm_one": false,
		"p2p_gen_type": "context",
		"p2p_key_size": 4,
		"p2p_num_keys": 4
	}
}